{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da2d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Original Dataset:\n",
      "\n",
      "   Order ID  Customer Name   Order Date   Product  Quantity  Unit Price  \\\n",
      "0      1001       John Doe   01/01/2024  Widget A      10.0        25.0   \n",
      "1      1002     Jane Smith   01/02/2024  Widget B       5.0        40.0   \n",
      "2      1003            NaN  2024/01/03'  Widget A       NaN        25.0   \n",
      "3      1004  Alice Johnson   04/01/2024  Widget C       3.0         NaN   \n",
      "4      1005      Bob Brown  2024/01/05'  Widget B      10.0        40.0   \n",
      "5      1006       John Doe   06/01/2024  Widget A       4.0        25.0   \n",
      "6      1001       John Doe   01/01/2024  Widget A      10.0        25.0   \n",
      "7      1007     Jane Smith   07/01/2024  Widget C      -6.0        70.0   \n",
      "\n",
      "   Total Revenue  \n",
      "0          250.0  \n",
      "1          200.0  \n",
      "2            NaN  \n",
      "3          210.0  \n",
      "4          400.0  \n",
      "5          100.0  \n",
      "6          250.0  \n",
      "7         -420.0  \n",
      "\n",
      "‚úÖ Dataset After Handling Missing Values:\n",
      "\n",
      "   Order ID  Customer Name  Order Date   Product  Quantity  Unit Price  \\\n",
      "0      1001       John Doe  01/01/2024  Widget A      10.0   25.000000   \n",
      "1      1002     Jane Smith  01/02/2024  Widget B       5.0   40.000000   \n",
      "2      1003        Unknown  2024/01/03  Widget A       5.0   25.000000   \n",
      "3      1004  Alice Johnson  04/01/2024  Widget C       3.0   35.714286   \n",
      "4      1005      Bob Brown  2024/01/05  Widget B      10.0   40.000000   \n",
      "5      1006       John Doe  06/01/2024  Widget A       4.0   25.000000   \n",
      "6      1001       John Doe  01/01/2024  Widget A      10.0   25.000000   \n",
      "7      1007     Jane Smith  07/01/2024  Widget C      -6.0   70.000000   \n",
      "\n",
      "   Total Revenue  \n",
      "0          250.0  \n",
      "1          200.0  \n",
      "2          125.0  \n",
      "3          210.0  \n",
      "4          400.0  \n",
      "5          100.0  \n",
      "6          250.0  \n",
      "7         -420.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DXB GADGETS\\AppData\\Local\\Temp\\ipykernel_12188\\4091431052.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Customer Name'].fillna(\"Unknown\", inplace=True)\n",
      "C:\\Users\\DXB GADGETS\\AppData\\Local\\Temp\\ipykernel_12188\\4091431052.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Quantity'].fillna(df['Quantity'].median(), inplace=True)\n",
      "C:\\Users\\DXB GADGETS\\AppData\\Local\\Temp\\ipykernel_12188\\4091431052.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Unit Price'].fillna(df['Unit Price'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#1) Missing values / Empty cells \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Sales.csv\")\n",
    "\n",
    "# Display original data\n",
    "print(\"\\nüìã Original Dataset:\\n\")\n",
    "print(df)\n",
    "\n",
    "# Clean date format preliminarily for easier handling later\n",
    "df['Order Date'] = df['Order Date'].astype(str).str.replace(\"'\", \"\", regex=False)\n",
    "\n",
    "# Convert numeric columns (they may have NaNs as strings)\n",
    "numeric_cols = ['Quantity', 'Unit Price', 'Total Revenue']\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values:\n",
    "\n",
    "# For Customer Name, fill with \"Unknown\"\n",
    "df['Customer Name'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# For Quantity, fill missing with median (most typical quantity)\n",
    "df['Quantity'].fillna(df['Quantity'].median(), inplace=True)\n",
    "\n",
    "# For Unit Price, fill missing with mean (average price)\n",
    "df['Unit Price'].fillna(df['Unit Price'].mean(), inplace=True)\n",
    "\n",
    "# For Total Revenue, if missing, calculate as Quantity * Unit Price\n",
    "df['Total Revenue'] = df.apply(\n",
    "    lambda row: row['Quantity'] * row['Unit Price'] if pd.isna(row['Total Revenue']) else row['Total Revenue'], axis=1)\n",
    "\n",
    "# Display cleaned data after handling missing values\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(\"\\n‚úÖ Dataset After Handling Missing Values:\\n\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb533e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Rows with Inconsistent or Unparseable Date Formats:\n",
      "\n",
      "    Order Date\n",
      "2  2024/01/03'\n",
      "4  2024/01/05'\n",
      "\n",
      "‚úÖ Dataset After Cleaning Date Formats:\n",
      "\n",
      "   Order ID  Customer Name  Order Date   Product  Quantity  Unit Price  \\\n",
      "0      1001       John Doe  2024-01-01  Widget A      10.0        25.0   \n",
      "1      1002     Jane Smith  2024-01-02  Widget B       5.0        40.0   \n",
      "2      1003            NaN  2024-03-01  Widget A       NaN        25.0   \n",
      "3      1004  Alice Johnson  2024-04-01  Widget C       3.0         NaN   \n",
      "4      1005      Bob Brown  2024-05-01  Widget B      10.0        40.0   \n",
      "5      1006       John Doe  2024-06-01  Widget A       4.0        25.0   \n",
      "6      1001       John Doe  2024-01-01  Widget A      10.0        25.0   \n",
      "7      1007     Jane Smith  2024-07-01  Widget C      -6.0        70.0   \n",
      "\n",
      "   Total Revenue  \n",
      "0          250.0  \n",
      "1          200.0  \n",
      "2            NaN  \n",
      "3          210.0  \n",
      "4          400.0  \n",
      "5          100.0  \n",
      "6          250.0  \n",
      "7         -420.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DXB GADGETS\\AppData\\Local\\Temp\\ipykernel_12188\\2526693193.py:13: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed_dates = pd.to_datetime(df['Order Date Cleaned'], errors='coerce', infer_datetime_format=True, dayfirst=False)\n",
      "C:\\Users\\DXB GADGETS\\AppData\\Local\\Temp\\ipykernel_12188\\2526693193.py:27: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed_dates = pd.to_datetime(df['Order Date'], errors='coerce', infer_datetime_format=True, dayfirst=False)\n",
      "C:\\Users\\DXB GADGETS\\AppData\\Local\\Temp\\ipykernel_12188\\2526693193.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  parsed_dates.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#2) Inconsistent date formats  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Sales.csv\")\n",
    "\n",
    "# Step 1: Detect inconsistent date formats\n",
    "\n",
    "# Clean apostrophes and spaces first for consistency in display\n",
    "df['Order Date Cleaned'] = df['Order Date'].astype(str).str.replace(\"'\", \"\", regex=False).str.strip()\n",
    "\n",
    "# Try parsing dates normally\n",
    "parsed_dates = pd.to_datetime(df['Order Date Cleaned'], errors='coerce', infer_datetime_format=True, dayfirst=False)\n",
    "\n",
    "# Rows where parsing failed\n",
    "inconsistent_dates = df[parsed_dates.isna()]\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Rows with Inconsistent or Unparseable Date Formats:\\n\")\n",
    "print(inconsistent_dates[['Order Date']])\n",
    "\n",
    "# Step 2: Fix dates\n",
    "\n",
    "# First replace 'Order Date' with cleaned strings\n",
    "df['Order Date'] = df['Order Date Cleaned']\n",
    "\n",
    "# Try parsing dates again with dayfirst=True where it was previously NaT\n",
    "parsed_dates = pd.to_datetime(df['Order Date'], errors='coerce', infer_datetime_format=True, dayfirst=False)\n",
    "mask = parsed_dates.isna()\n",
    "parsed_dates.loc[mask] = pd.to_datetime(df.loc[mask, 'Order Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Fill missing dates by forward fill\n",
    "parsed_dates.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Update dataframe with fixed and uniform dates\n",
    "df['Order Date'] = parsed_dates.dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Drop helper column\n",
    "df.drop(columns=['Order Date Cleaned'], inplace=True)\n",
    "\n",
    "# Display cleaned dataset\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(\"\\n‚úÖ Dataset After Cleaning Date Formats:\\n\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Duplicate Rows Detected (including original duplicates):\n",
      "\n",
      "   Order ID Customer Name  Order Date   Product  Quantity  Unit Price  \\\n",
      "0      1001      John Doe  01/01/2024  Widget A      10.0        25.0   \n",
      "6      1001      John Doe  01/01/2024  Widget A      10.0        25.0   \n",
      "\n",
      "   Total Revenue  \n",
      "0          250.0  \n",
      "6          250.0  \n",
      "\n",
      "‚úÖ Dataset After Removing Duplicate Rows:\n",
      "\n",
      "   Order ID  Customer Name   Order Date   Product  Quantity  Unit Price  \\\n",
      "0      1001       John Doe   01/01/2024  Widget A      10.0        25.0   \n",
      "1      1002     Jane Smith   01/02/2024  Widget B       5.0        40.0   \n",
      "2      1003            NaN  2024/01/03'  Widget A       NaN        25.0   \n",
      "3      1004  Alice Johnson   04/01/2024  Widget C       3.0         NaN   \n",
      "4      1005      Bob Brown  2024/01/05'  Widget B      10.0        40.0   \n",
      "5      1006       John Doe   06/01/2024  Widget A       4.0        25.0   \n",
      "7      1007     Jane Smith   07/01/2024  Widget C      -6.0        70.0   \n",
      "\n",
      "   Total Revenue  \n",
      "0          250.0  \n",
      "1          200.0  \n",
      "2            NaN  \n",
      "3          210.0  \n",
      "4          400.0  \n",
      "5          100.0  \n",
      "7         -420.0  \n"
     ]
    }
   ],
   "source": [
    "#3) Duplicate rows.\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Sales.csv\")\n",
    "\n",
    "# Step 1: Detect duplicate rows (considering all columns)\n",
    "duplicates = df[df.duplicated(keep=False)]  # show all duplicates, including original rows\n",
    "\n",
    "print(\"\\nüîç Duplicate Rows Detected (including original duplicates):\\n\")\n",
    "print(duplicates)\n",
    "\n",
    "# Step 2: Remove duplicate rows keeping the first occurrence\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# Step 3: Display dataset after removing duplicates\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(\"\\n‚úÖ Dataset After Removing Duplicate Rows:\\n\")\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Rows with Wrong Data Detected:\n",
      "\n",
      "   Order ID  Customer Name  Order Date   Product  Quantity  Unit Price  \\\n",
      "7      1007     Jane Smith  07/01/2024  Widget C      -6.0        70.0   \n",
      "2      1003            NaN  2024/01/03  Widget A       NaN        25.0   \n",
      "3      1004  Alice Johnson  04/01/2024  Widget C       3.0         NaN   \n",
      "\n",
      "   Total Revenue  \n",
      "7         -420.0  \n",
      "2            NaN  \n",
      "3          210.0  \n",
      "\n",
      "‚úÖ Dataset After Removing Wrong Data:\n",
      "\n",
      "   Order ID Customer Name  Order Date   Product  Quantity  Unit Price  \\\n",
      "0      1001      John Doe  01/01/2024  Widget A      10.0        25.0   \n",
      "1      1002    Jane Smith  01/02/2024  Widget B       5.0        40.0   \n",
      "4      1005     Bob Brown  2024/01/05  Widget B      10.0        40.0   \n",
      "5      1006      John Doe  06/01/2024  Widget A       4.0        25.0   \n",
      "6      1001      John Doe  01/01/2024  Widget A      10.0        25.0   \n",
      "\n",
      "   Total Revenue  \n",
      "0          250.0  \n",
      "1          200.0  \n",
      "4          400.0  \n",
      "5          100.0  \n",
      "6          250.0  \n"
     ]
    }
   ],
   "source": [
    "#4) Wrong data \n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Sales.csv\")\n",
    "\n",
    "# Clean 'Order Date' for consistency (optional but recommended)\n",
    "df['Order Date'] = df['Order Date'].astype(str).str.replace(\"'\", \"\", regex=False).str.strip()\n",
    "\n",
    "# Convert numeric columns to numeric dtype for safe comparison\n",
    "numeric_cols = ['Quantity', 'Unit Price', 'Total Revenue']\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Identify wrong data conditions\n",
    "wrong_quantity = df[df['Quantity'] <= 0]\n",
    "wrong_unit_price = df[df['Unit Price'] <= 0]\n",
    "wrong_revenue = df[df['Total Revenue'] <= 0]\n",
    "\n",
    "# Check inconsistency between Total Revenue and Quantity * Unit Price (allowing small rounding difference)\n",
    "revenue_mismatch = df[~((df['Total Revenue'] - (df['Quantity'] * df['Unit Price'])).abs() < 0.01)]\n",
    "\n",
    "# Combine all wrong data rows (using index to avoid duplicates)\n",
    "wrong_data = pd.concat([wrong_quantity, wrong_unit_price, wrong_revenue, revenue_mismatch]).drop_duplicates()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Rows with Wrong Data Detected:\\n\")\n",
    "print(wrong_data)\n",
    "\n",
    "# Remove wrong data rows from original dataframe\n",
    "df_cleaned = df.drop(index=wrong_data.index)\n",
    "\n",
    "# Display cleaned dataset\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(\"\\n‚úÖ Dataset After Removing Wrong Data:\\n\")\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Original Columns in Dataset:\n",
      "\n",
      "['Order ID', 'Customer Name', 'Order Date', 'Product', 'Quantity', 'Unit Price', 'Total Revenue']\n",
      "\n",
      "üóëÔ∏è Unnecessary Columns to Drop:\n",
      "\n",
      "No unnecessary columns found.\n",
      "\n",
      "‚úÖ Dataset After Dropping Unnecessary Columns:\n",
      "\n",
      "   Order ID  Customer Name   Order Date   Product  Quantity  Unit Price  \\\n",
      "0      1001       John Doe   01/01/2024  Widget A      10.0        25.0   \n",
      "1      1002     Jane Smith   01/02/2024  Widget B       5.0        40.0   \n",
      "2      1003            NaN  2024/01/03'  Widget A       NaN        25.0   \n",
      "3      1004  Alice Johnson   04/01/2024  Widget C       3.0         NaN   \n",
      "4      1005      Bob Brown  2024/01/05'  Widget B      10.0        40.0   \n",
      "5      1006       John Doe   06/01/2024  Widget A       4.0        25.0   \n",
      "6      1001       John Doe   01/01/2024  Widget A      10.0        25.0   \n",
      "7      1007     Jane Smith   07/01/2024  Widget C      -6.0        70.0   \n",
      "\n",
      "   Total Revenue  \n",
      "0          250.0  \n",
      "1          200.0  \n",
      "2            NaN  \n",
      "3          210.0  \n",
      "4          400.0  \n",
      "5          100.0  \n",
      "6          250.0  \n",
      "7         -420.0  \n"
     ]
    }
   ],
   "source": [
    "#5) Unnecessary columns that are not relevant to the analysis. \n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Sales.csv\")\n",
    "\n",
    "# Step 1: Show original columns\n",
    "print(\"\\nüìã Original Columns in Dataset:\\n\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Step 2: Define relevant columns\n",
    "relevant_cols = ['Order ID', 'Customer Name', 'Order Date', 'Product', 'Quantity', 'Unit Price', 'Total Revenue']\n",
    "\n",
    "# Step 3: Identify unnecessary columns (not in relevant_cols)\n",
    "unnecessary_cols = [col for col in df.columns if col not in relevant_cols]\n",
    "\n",
    "print(\"\\nüóëÔ∏è Unnecessary Columns to Drop:\\n\")\n",
    "print(unnecessary_cols if unnecessary_cols else \"No unnecessary columns found.\")\n",
    "\n",
    "# Step 4: Drop unnecessary columns if any\n",
    "df_cleaned = df.drop(columns=unnecessary_cols) if unnecessary_cols else df.copy()\n",
    "\n",
    "# Step 5: Display cleaned dataset\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(\"\\n‚úÖ Dataset After Dropping Unnecessary Columns:\\n\")\n",
    "print(df_cleaned)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
